# 数据源配置
spring:
    datasource:
        type: com.alibaba.druid.pool.DruidDataSource
        driverClassName: com.mysql.cj.jdbc.Driver
        druid:
            # 主库数据源
            master:
                url: jdbc:mysql://49.232.190.104:3306/circle?useUnicode=true&characterEncoding=utf8&zeroDateTimeBehavior=convertToNull&useSSL=true&serverTimezone=GMT%2B8
                username: root
                password: Root123!@#
            # 从库数据源
            slave:
                # 从数据源开关/默认关闭
                enabled: false
                url: 
                username: 
                password: 
            # 初始连接数
            initialSize: 5
            # 最小连接池数量
            minIdle: 10
            # 最大连接池数量
            maxActive: 20
            # 配置获取连接等待超时的时间
            maxWait: 60000
            # 配置连接超时时间
            connectTimeout: 30000
            # 配置网络超时时间
            socketTimeout: 60000
            # 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒
            timeBetweenEvictionRunsMillis: 60000
            # 配置一个连接在池中最小生存的时间，单位是毫秒
            minEvictableIdleTimeMillis: 300000
            # 配置一个连接在池中最大生存的时间，单位是毫秒
            maxEvictableIdleTimeMillis: 900000
            # 配置检测连接是否有效
            validationQuery: SELECT 1 FROM DUAL
            testWhileIdle: true
            testOnBorrow: false
            testOnReturn: false
            webStatFilter: 
                enabled: true
            statViewServlet:
                enabled: true
                # 设置白名单，不填则允许所有访问
                allow:
                url-pattern: /druid/*
                # 控制台管理用户名和密码
                login-username: ruoyi
                login-password: 123456
            filter:
                stat:
                    enabled: true
                    # 慢SQL记录
                    log-slow-sql: true
                    slow-sql-millis: 1000
                    merge-sql: true
                wall:
                    config:
                        multi-statement-allow: true

    kafka:
        bootstrap-servers: 49.232.190.104:9092 #这个是kafka的地址,对应你server.properties中配置的
        producer:
            batch-size: 16384 #批量大小
            acks: -1 #应答级别:多少个分区副本备份完成时向生产者发送ack确认(可选0、1、all/-1)
            retries: 10 # 消息发送重试次数
            #      transaction-id-prefix:  tx_1 #事务id前缀
            buffer-memory: 33554432
            key-serializer: org.apache.kafka.common.serialization.StringSerializer
            value-serializer: org.apache.kafka.common.serialization.StringSerializer
            properties:
                linger:
                    ms: 2000 #提交延迟
        #        partitioner: #指定分区器
        #          class: com.example.kafkademo.config.CustomizePartitioner
        consumer:
            group-id: myGroup #默认的消费组ID
            enable-auto-commit: true #是否自动提交offset
            auto-commit-interval: 2000 #提交offset延时
            # 当kafka中没有初始offset或offset超出范围时将自动重置offset
            # earliest:重置为分区中最小的offset;
            # latest:重置为分区中最新的offset(消费分区中新产生的数据);
            # none:只要有一个分区不存在已提交的offset,就抛出异常;
            auto-offset-reset: latest
            max-poll-records: 500 #单次拉取消息的最大条数
            key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
            value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
            properties:
                session:
                    timeout:
                        ms: 120000 # 消费会话超时时间（超过这个时间 consumer 没有发送心跳，就会触发 rebalance 操作）
                request:
                    timeout:
                        ms: 18000 # 消费请求的超时时间
        listener:
            missing-topics-fatal: false # consumer listener topics 不存在时，启动项目就会报错
            type: batch #设置批量消费

